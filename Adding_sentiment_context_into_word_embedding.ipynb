{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1gAUNAe1cYs1Q9Krs4sOtxVQ7vKIhfGSr",
      "authorship_tag": "ABX9TyNSgXr6ZxwaxZlBXixxXHvA"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLatFR0Km1mA"
      },
      "source": [
        "# DataFrame\n",
        "import pandas as pd\n",
        "\n",
        "# Matplot\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Scikit-learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense, Dropout, Embedding, Flatten, Conv1D, MaxPooling1D, LSTM, Bidirectional\n",
        "from keras import utils\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from keras import optimizers\n",
        "\n",
        "# nltk\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from  nltk.stem import SnowballStemmer\n",
        "\n",
        "# Word2vec\n",
        "import gensim\n",
        "\n",
        "# Utility\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "from collections import Counter\n",
        "import logging\n",
        "import time\n",
        "import pickle\n",
        "import itertools\n",
        "\n",
        "# Set log\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dz2xan_nNKC"
      },
      "source": [
        "# DATASET\n",
        "DATASET_ENCODING = \"ISO-8859-1\"\n",
        "DATASET_COLUMNS = [\"sentiment\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
        "\n",
        "TRAIN_SIZE = 0.8\n",
        "\n",
        "# TEXT CLENAING\n",
        "TEXT_CLEANING_RE = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n",
        "\n",
        "# WORD2VEC \n",
        "W2V_SIZE = 300\n",
        "W2V_WINDOW = 7\n",
        "W2V_EPOCH = 32\n",
        "W2V_MIN_COUNT = 10\n",
        "\n",
        "# KERAS\n",
        "SEQUENCE_LENGTH = 300\n",
        "EPOCHS = 8\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# SENTIMENT\n",
        "POSITIVE = \"POSITIVE\"\n",
        "NEGATIVE = \"NEGATIVE\"\n",
        "NEUTRAL = \"NEUTRAL\"\n",
        "SENTIMENT_THRESHOLDS = (0.4, 0.7)\n",
        "\n",
        "# EXPORT\n",
        "KERAS_MODEL = \"teacher_model.h5\"\n",
        "WORD2VEC_MODEL = \"w2v_model.w2v\"\n",
        "TOKENIZER_MODEL = \"teacher_tokenizer.pkl\"\n",
        "ENCODER_MODEL = \"teacher_encoder.pkl\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsshIv5wm9Bu"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Data science/cp_dataset/tweet_hotel.csv\",\n",
        "                 encoding = DATASET_ENCODING)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtBsjkeKHvt6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "72c7364a-8e35-407d-b903-3dbe87eeefc8"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>âvirus leak from hotel quarantine which be m...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>the doctor and a sexy fish stay at a hotel in ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>hotel emporium have create the perfect replace...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>sunainapatnaik sloganmurugan you have to pay r...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>worldâs first hotel which run on electricity...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101155</th>\n",
              "      <td>101155</td>\n",
              "      <td>drnaumanniaz bhattimajid during practice match...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101156</th>\n",
              "      <td>101156</td>\n",
              "      <td>iâm annoy the ac die a few day ago iâm thi...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101157</th>\n",
              "      <td>101157</td>\n",
              "      <td>misfitpoise i legit have see this movie time a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101158</th>\n",
              "      <td>101158</td>\n",
              "      <td>anthonyhotels have you see the indoor waterpar...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101159</th>\n",
              "      <td>101159</td>\n",
              "      <td>he be stay in a hotel that cost million yen a ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>101160 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unnamed: 0  ... sentiment\n",
              "0                0  ...         1\n",
              "1                1  ...         4\n",
              "2                2  ...         5\n",
              "3                3  ...         1\n",
              "4                4  ...         5\n",
              "...            ...  ...       ...\n",
              "101155      101155  ...         1\n",
              "101156      101156  ...         3\n",
              "101157      101157  ...         1\n",
              "101158      101158  ...         1\n",
              "101159      101159  ...         1\n",
              "\n",
              "[101160 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttpi60DFUN4v",
        "outputId": "a2fe4564-04da-46e6-a64f-deb7e6bd2e61"
      },
      "source": [
        "df['sentiment'] = df['sentiment'].replace(2,1)\n",
        "df['sentiment'] = df['sentiment'].replace(4,5)\n",
        "df.drop(df[df['sentiment'] == 3].index, inplace = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-09-15 10:00:40,420 : INFO : NumExpr defaulting to 2 threads.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1InDrMumpZM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fd24f5e-a5b1-42dc-8f42-9522c26d8bf7"
      },
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "stop_words = stopwords.words(\"english\")\n",
        "nltk.download('sentiwordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/sentiwordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQWPC-bUNYGm"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.tag import pos_tag\n",
        "\n",
        "def preprocess(text, lem=True):\n",
        "    # Remove link,user and special characters\n",
        "    text = re.sub(TEXT_CLEANING_RE, ' ', str(text).lower()).strip()\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    split_text = text.split()\n",
        "    tokens = []\n",
        "    if lem:\n",
        "        for word, tag in pos_tag(split_text):\n",
        "            if tag.startswith('NN'):\n",
        "                pos = 'n'\n",
        "            elif tag.startswith('VB'):\n",
        "                pos = 'v'\n",
        "            else:\n",
        "                pos = 'a'\n",
        "            tokens.append(lemmatizer.lemmatize(word, pos))\n",
        "    else:\n",
        "        tokens.append(split_text)\n",
        "    return \" \".join(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl9jrzN1Nopt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4563da97-cee8-4f0f-aae6-0982b0fe507a"
      },
      "source": [
        "%%time\n",
        "df.text = df.text.apply(lambda x: preprocess(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1min 36s, sys: 1.24 s, total: 1min 37s\n",
            "Wall time: 1min 39s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqBYJuxQAS9f"
      },
      "source": [
        "def preprocessno(text):\n",
        "    text = re.sub(r'[0-9]', ' ', str(text).lower()).strip()\n",
        "    return (text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmNVQLJSL6Y2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b18b7fc2-dbda-41f1-aca2-ad5306538fb1"
      },
      "source": [
        "%%time\n",
        "df.text = df.text.apply(lambda x: preprocessno(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 215 ms, sys: 971 µs, total: 216 ms\n",
            "Wall time: 216 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmUM_ftGUEtx",
        "outputId": "1be36137-8c93-4cac-c74a-72cdd741ee98"
      },
      "source": [
        "df_train, df_test = train_test_split(df, test_size=1-TRAIN_SIZE, random_state=42)\n",
        "print(\"TRAIN size:\", len(df_train))\n",
        "print(\"TEST size:\", len(df_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN size: 70918\n",
            "TEST size: 17730\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oP0axwMvkMXz",
        "outputId": "a6bd311f-bb8d-4ece-88a7-4a413a54912c"
      },
      "source": [
        "df[\"sentiment\"].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m01oe9bKPfLl"
      },
      "source": [
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "stopwords.append(\"hotel\")\n",
        "stopwords.append(\"room\")\n",
        "stopwords.append(\"get\")\n",
        "stopwords.append(\"go\")\n",
        "stopwords.append(\"stay\")\n",
        "stopwords.append(\"one\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wo57GwseGGeS"
      },
      "source": [
        "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    tokenized_text = tokenizer.tokenize(text)\n",
        "    text = [w for w in tokenized_text if w not in stopwords]\n",
        "    combined_text = ' '.join(text)\n",
        "    return combined_text\n",
        "\n",
        "df.text = df.text.apply(str).apply(lambda x: remove_stopwords(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3xXX-17Crw3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94b9e35c-caab-4345-ecbd-81538b5679cf"
      },
      "source": [
        "print(\"Dataset size:\", len(df))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size: 88648\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR_IgFxiruZ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10ed3fe5-93e1-43ec-d720-ad699ebf98bc"
      },
      "source": [
        "res = df['text'].str.split().str.len().max()\n",
        "\n",
        "print(\"The maximum length in words are : \" +  str(res))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The maximum length in words are : 22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlY6JgePOvzw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a480bcd-f570-405f-e18a-113b6ce11bbe"
      },
      "source": [
        "%%time\n",
        "documents = [_text.split() for _text in df_train.text]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 337 ms, sys: 38.1 ms, total: 375 ms\n",
            "Wall time: 375 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfO9E75-QQwN"
      },
      "source": [
        "w2v_model = gensim.models.word2vec.Word2Vec(size=92, \n",
        "                                            window=W2V_WINDOW, \n",
        "                                            min_count=50, \n",
        "                                            workers=8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5n5iF6fqQWy4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b287a9f-6975-4fb7-cc1a-2253405bd0ef"
      },
      "source": [
        "w2v_model.build_vocab(documents)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-09-15 10:02:26,299 : INFO : collecting all words and their counts\n",
            "2021-09-15 10:02:26,301 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2021-09-15 10:02:26,350 : INFO : PROGRESS: at sentence #10000, processed 155279 words, keeping 20439 word types\n",
            "2021-09-15 10:02:26,397 : INFO : PROGRESS: at sentence #20000, processed 310700 words, keeping 32642 word types\n",
            "2021-09-15 10:02:26,443 : INFO : PROGRESS: at sentence #30000, processed 465561 words, keeping 42757 word types\n",
            "2021-09-15 10:02:26,494 : INFO : PROGRESS: at sentence #40000, processed 620132 words, keeping 52095 word types\n",
            "2021-09-15 10:02:26,539 : INFO : PROGRESS: at sentence #50000, processed 775991 words, keeping 60881 word types\n",
            "2021-09-15 10:02:26,583 : INFO : PROGRESS: at sentence #60000, processed 929890 words, keeping 68740 word types\n",
            "2021-09-15 10:02:26,631 : INFO : PROGRESS: at sentence #70000, processed 1086082 words, keeping 76409 word types\n",
            "2021-09-15 10:02:26,636 : INFO : collected 77122 word types from a corpus of 1100166 raw words and 70918 sentences\n",
            "2021-09-15 10:02:26,639 : INFO : Loading a fresh vocabulary\n",
            "2021-09-15 10:02:26,685 : INFO : effective_min_count=50 retains 1900 unique words (2% of original 77122, drops 75222)\n",
            "2021-09-15 10:02:26,686 : INFO : effective_min_count=50 leaves 896324 word corpus (81% of original 1100166, drops 203842)\n",
            "2021-09-15 10:02:26,699 : INFO : deleting the raw counts dictionary of 77122 items\n",
            "2021-09-15 10:02:26,702 : INFO : sample=0.001 downsamples 52 most-common words\n",
            "2021-09-15 10:02:26,708 : INFO : downsampling leaves estimated 608411 word corpus (67.9% of prior 896324)\n",
            "2021-09-15 10:02:26,719 : INFO : estimated required memory for 1900 words and 92 dimensions: 2348400 bytes\n",
            "2021-09-15 10:02:26,722 : INFO : resetting layer weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJ2tpBnMWUwU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0770cf59-0ae0-4217-f0c2-d13759aa8189"
      },
      "source": [
        "words = w2v_model.wv.vocab.keys()\n",
        "vocab_size = len(words)\n",
        "print(\"Vocab size\", vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size 1900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dKouK5SXOes",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21af6c76-490c-44d3-9a72-e5ac852ded78"
      },
      "source": [
        "%%time\n",
        "w2v_model.train(documents, total_examples=len(documents), epochs=W2V_EPOCH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-09-15 10:02:27,165 : INFO : training model with 8 workers on 1900 vocabulary and 92 features, using sg=0 hs=0 sample=0.001 negative=5 window=7\n",
            "2021-09-15 10:02:28,195 : INFO : EPOCH 1 - PROGRESS: at 61.78% examples, 371813 words/s, in_qsize 14, out_qsize 4\n",
            "2021-09-15 10:02:28,600 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2021-09-15 10:02:28,619 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2021-09-15 10:02:28,642 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2021-09-15 10:02:28,649 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2021-09-15 10:02:28,651 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-09-15 10:02:28,658 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-09-15 10:02:28,661 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-09-15 10:02:28,663 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-09-15 10:02:28,665 : INFO : EPOCH - 1 : training on 1100166 raw words (608841 effective words) took 1.5s, 411264 effective words/s\n",
            "2021-09-15 10:02:29,726 : INFO : EPOCH 2 - PROGRESS: at 68.14% examples, 396942 words/s, in_qsize 15, out_qsize 0\n",
            "2021-09-15 10:02:30,067 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2021-09-15 10:02:30,100 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2021-09-15 10:02:30,102 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2021-09-15 10:02:30,106 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2021-09-15 10:02:30,114 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-09-15 10:02:30,117 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-09-15 10:02:30,123 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-09-15 10:02:30,126 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-09-15 10:02:30,128 : INFO : EPOCH - 2 : training on 1100166 raw words (608471 effective words) took 1.4s, 420840 effective words/s\n",
            "2021-09-15 10:02:31,159 : INFO : EPOCH 3 - PROGRESS: at 66.34% examples, 395323 words/s, in_qsize 16, out_qsize 2\n",
            "2021-09-15 10:02:31,512 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2021-09-15 10:02:31,523 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2021-09-15 10:02:31,542 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2021-09-15 10:02:31,554 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2021-09-15 10:02:31,561 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-09-15 10:02:31,562 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-09-15 10:02:31,568 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-09-15 10:02:31,577 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-09-15 10:02:31,578 : INFO : EPOCH - 3 : training on 1100166 raw words (608891 effective words) took 1.4s, 423128 effective words/s\n",
            "2021-09-15 10:02:32,601 : INFO : EPOCH 4 - PROGRESS: at 66.34% examples, 399967 words/s, in_qsize 15, out_qsize 0\n",
            "2021-09-15 10:02:32,996 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2021-09-15 10:02:32,998 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2021-09-15 10:02:33,000 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2021-09-15 10:02:33,025 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2021-09-15 10:02:33,028 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-09-15 10:02:33,029 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-09-15 10:02:33,040 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-09-15 10:02:33,043 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-09-15 10:02:33,045 : INFO : EPOCH - 4 : training on 1100166 raw words (608642 effective words) took 1.5s, 419011 effective words/s\n",
            "2021-09-15 10:02:34,059 : INFO : EPOCH 5 - PROGRESS: at 69.01% examples, 419207 words/s, in_qsize 14, out_qsize 0\n",
            "2021-09-15 10:02:34,436 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2021-09-15 10:02:34,447 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2021-09-15 10:02:34,449 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2021-09-15 10:02:34,461 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2021-09-15 10:02:34,463 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-09-15 10:02:34,464 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-09-15 10:02:34,480 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-09-15 10:02:34,487 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-09-15 10:02:34,489 : INFO : EPOCH - 5 : training on 1100166 raw words (608781 effective words) took 1.4s, 425431 effective words/s\n",
            "2021-09-15 10:02:35,524 : INFO : EPOCH 6 - PROGRESS: at 69.02% examples, 411396 words/s, in_qsize 15, out_qsize 0\n",
            "2021-09-15 10:02:35,874 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2021-09-15 10:02:35,889 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2021-09-15 10:02:35,893 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2021-09-15 10:02:35,902 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2021-09-15 10:02:35,907 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-09-15 10:02:35,914 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-09-15 10:02:35,932 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-09-15 10:02:35,936 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-09-15 10:02:35,938 : INFO : EPOCH - 6 : training on 1100166 raw words (608374 effective words) took 1.4s, 424265 effective words/s\n",
            "2021-09-15 10:02:36,951 : INFO : EPOCH 7 - PROGRESS: at 66.28% examples, 402496 words/s, in_qsize 15, out_qsize 0\n",
            "2021-09-15 10:02:37,341 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2021-09-15 10:02:37,361 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2021-09-15 10:02:37,379 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2021-09-15 10:02:37,381 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2021-09-15 10:02:37,384 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-09-15 10:02:37,388 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-09-15 10:02:37,392 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-09-15 10:02:37,399 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-09-15 10:02:37,402 : INFO : EPOCH - 7 : training on 1100166 raw words (608200 effective words) took 1.5s, 418954 effective words/s\n",
            "2021-09-15 10:02:38,422 : INFO : EPOCH 8 - PROGRESS: at 62.69% examples, 378306 words/s, in_qsize 16, out_qsize 3\n",
            "2021-09-15 10:02:38,820 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2021-09-15 10:02:38,823 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2021-09-15 10:02:38,834 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2021-09-15 10:02:38,847 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2021-09-15 10:02:38,855 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-09-15 10:02:38,862 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-09-15 10:02:38,864 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-09-15 10:02:38,876 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-09-15 10:02:38,877 : INFO : EPOCH - 8 : training on 1100166 raw words (608161 effective words) took 1.5s, 416038 effective words/s\n",
            "2021-09-15 10:02:39,895 : INFO : EPOCH 9 - PROGRESS: at 66.32% examples, 401369 words/s, in_qsize 15, out_qsize 0\n",
            "2021-09-15 10:02:40,277 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2021-09-15 10:02:40,281 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2021-09-15 10:02:40,289 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2021-09-15 10:02:40,291 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2021-09-15 10:02:40,303 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-09-15 10:02:40,317 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-09-15 10:02:40,320 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-09-15 10:02:40,325 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-09-15 10:02:40,326 : INFO : EPOCH - 9 : training on 1100166 raw words (608181 effective words) took 1.4s, 423826 effective words/s\n",
            "2021-09-15 10:02:41,372 : INFO : EPOCH 10 - PROGRESS: at 67.25% examples, 397880 words/s, in_qsize 15, out_qsize 0\n",
            "2021-09-15 10:02:41,730 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2021-09-15 10:02:41,737 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2021-09-15 10:02:41,740 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2021-09-15 10:02:41,746 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2021-09-15 10:02:41,751 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-09-15 10:02:41,754 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-09-15 10:02:41,755 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-09-15 10:02:41,757 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-09-15 10:02:41,759 : INFO : EPOCH - 10 : training on 1100166 raw words (608031 effective words) took 1.4s, 430486 effective words/s\n",
            "2021-09-15 10:02:42,801 : INFO : EPOCH 11 - PROGRESS: at 65.44% examples, 389259 words/s, in_qsize 15, out_qsize 0\n",
            "2021-09-15 10:02:43,168 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2021-09-15 10:02:43,171 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2021-09-15 10:02:43,177 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2021-09-15 10:02:43,184 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2021-09-15 10:02:43,208 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-09-15 10:02:43,213 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-09-15 10:02:43,217 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-09-15 10:02:43,221 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-09-15 10:02:43,223 : INFO : EPOCH - 11 : training on 1100166 raw words (608022 effective words) took 1.4s, 421630 effective words/s\n",
            "2021-09-15 10:02:44,276 : INFO : EPOCH 12 - PROGRESS: at 67.24% examples, 393066 words/s, in_qsize 15, out_qsize 0\n",
            "2021-09-15 10:02:44,616 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2021-09-15 10:02:44,619 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2021-09-15 10:02:44,629 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2021-09-15 10:02:44,640 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2021-09-15 10:02:44,643 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-09-15 10:02:44,656 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-09-15 10:02:44,667 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-09-15 10:02:44,679 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-09-15 10:02:44,681 : INFO : EPOCH - 12 : training on 1100166 raw words (608174 effective words) took 1.4s, 421164 effective words/s\n",
            "2021-09-15 10:02:45,741 : INFO : EPOCH 13 - PROGRESS: at 68.14% examples, 396285 words/s, in_qsize 14, out_qsize 1\n",
            "2021-09-15 10:02:46,059 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2021-09-15 10:02:46,070 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2021-09-15 10:02:46,073 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2021-09-15 10:02:46,093 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2021-09-15 10:02:46,096 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-09-15 10:02:46,111 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-09-15 10:02:46,113 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-09-15 10:02:46,116 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-09-15 10:02:46,119 : INFO : EPOCH - 13 : training on 1100166 raw words (608229 effective words) took 1.4s, 427416 effective words/s\n",
            "2021-09-15 10:02:47,166 : INFO : EPOCH 14 - PROGRESS: at 67.24% examples, 396953 words/s, in_qsize 15, out_qsize 0\n",
            "2021-09-15 10:02:47,529 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2021-09-15 10:02:47,535 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2021-09-15 10:02:47,542 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2021-09-15 10:02:47,555 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2021-09-15 10:02:47,561 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-09-15 10:02:47,566 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-09-15 10:02:47,569 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-09-15 10:02:47,571 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-09-15 10:02:47,572 : INFO : EPOCH - 14 : training on 1100166 raw words (608915 effective words) took 1.4s, 423869 effective words/s\n",
            "2021-09-15 10:02:48,614 : INFO : EPOCH 15 - PROGRESS: at 66.32% examples, 395732 words/s, in_qsize 15, out_qsize 0\n",
            "2021-09-15 10:02:48,981 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2021-09-15 10:02:48,989 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2021-09-15 10:02:48,991 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2021-09-15 10:02:48,997 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2021-09-15 10:02:49,000 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-09-15 10:02:49,014 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-09-15 10:02:49,021 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-09-15 10:02:49,027 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-09-15 10:02:49,029 : INFO : EPOCH - 15 : training on 1100166 raw words (608031 effective words) took 1.4s, 424205 effective words/s\n",
            "2021-09-15 10:02:50,076 : INFO : EPOCH 16 - PROGRESS: at 69.01% examples, 405926 words/s, in_qsize 14, out_qsize 1\n",
            "2021-09-15 10:02:50,416 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2021-09-15 10:02:50,431 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2021-09-15 10:02:50,437 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2021-09-15 10:02:50,445 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2021-09-15 10:02:50,455 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-09-15 10:02:50,467 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-09-15 10:02:50,475 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-09-15 10:02:50,477 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-09-15 10:02:50,481 : INFO : EPOCH - 16 : training on 1100166 raw words (608403 effective words) took 1.4s, 423101 effective words/s\n",
            "2021-09-15 10:02:51,536 : INFO : EPOCH 17 - PROGRESS: at 68.12% examples, 398523 words/s, in_qsize 16, out_qsize 0\n",
            "2021-09-15 10:02:51,880 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2021-09-15 10:02:51,883 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2021-09-15 10:02:51,895 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2021-09-15 10:02:51,902 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2021-09-15 10:02:51,909 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-09-15 10:02:51,912 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-09-15 10:02:51,914 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-09-15 10:02:51,919 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-09-15 10:02:51,921 : INFO : EPOCH - 17 : training on 1100166 raw words (608711 effective words) took 1.4s, 427416 effective words/s\n",
            "2021-09-15 10:02:52,963 : INFO : EPOCH 18 - PROGRESS: at 65.43% examples, 395815 words/s, in_qsize 15, out_qsize 4\n",
            "2021-09-15 10:02:53,323 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2021-09-15 10:02:53,331 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2021-09-15 10:02:53,334 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2021-09-15 10:02:53,340 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2021-09-15 10:02:53,343 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-09-15 10:02:53,346 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-09-15 10:02:53,352 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-09-15 10:02:53,356 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-09-15 10:02:53,358 : INFO : EPOCH - 18 : training on 1100166 raw words (608210 effective words) took 1.4s, 429122 effective words/s\n",
            "2021-09-15 10:02:54,469 : INFO : EPOCH 19 - PROGRESS: at 69.94% examples, 390016 words/s, in_qsize 14, out_qsize 1\n",
            "2021-09-15 10:02:54,768 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2021-09-15 10:02:54,778 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2021-09-15 10:02:54,783 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2021-09-15 10:02:54,790 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2021-09-15 10:02:54,798 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-09-15 10:02:54,800 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-09-15 10:02:54,809 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-09-15 10:02:54,814 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-09-15 10:02:54,817 : INFO : EPOCH - 19 : training on 1100166 raw words (608485 effective words) took 1.4s, 423078 effective words/s\n",
            "2021-09-15 10:02:55,852 : INFO : EPOCH 20 - PROGRESS: at 64.52% examples, 385492 words/s, in_qsize 12, out_qsize 4\n",
            "2021-09-15 10:02:56,211 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2021-09-15 10:02:56,220 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2021-09-15 10:02:56,224 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2021-09-15 10:02:56,232 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2021-09-15 10:02:56,262 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-09-15 10:02:56,269 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-09-15 10:02:56,276 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-09-15 10:02:56,278 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-09-15 10:02:56,280 : INFO : EPOCH - 20 : training on 1100166 raw words (608436 effective words) took 1.4s, 420935 effective words/s\n",
            "2021-09-15 10:02:57,301 : INFO : EPOCH 21 - PROGRESS: at 65.43% examples, 397104 words/s, in_qsize 15, out_qsize 0\n",
            "2021-09-15 10:02:57,674 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2021-09-15 10:02:57,686 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2021-09-15 10:02:57,695 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2021-09-15 10:02:57,704 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2021-09-15 10:02:57,723 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-09-15 10:02:57,731 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-09-15 10:02:57,736 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-09-15 10:02:57,742 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-09-15 10:02:57,744 : INFO : EPOCH - 21 : training on 1100166 raw words (609279 effective words) took 1.4s, 421553 effective words/s\n",
            "2021-09-15 10:02:58,756 : INFO : EPOCH 22 - PROGRESS: at 65.42% examples, 396909 words/s, in_qsize 16, out_qsize 2\n",
            "2021-09-15 10:02:59,146 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2021-09-15 10:02:59,151 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2021-09-15 10:02:59,160 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2021-09-15 10:02:59,167 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2021-09-15 10:02:59,170 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-09-15 10:02:59,175 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-09-15 10:02:59,186 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-09-15 10:02:59,197 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-09-15 10:02:59,199 : INFO : EPOCH - 22 : training on 1100166 raw words (607854 effective words) took 1.4s, 420976 effective words/s\n",
            "2021-09-15 10:03:00,243 : INFO : EPOCH 23 - PROGRESS: at 68.14% examples, 404837 words/s, in_qsize 15, out_qsize 0\n",
            "2021-09-15 10:03:00,595 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2021-09-15 10:03:00,598 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2021-09-15 10:03:00,610 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2021-09-15 10:03:00,617 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2021-09-15 10:03:00,621 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-09-15 10:03:00,641 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-09-15 10:03:00,646 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-09-15 10:03:00,654 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-09-15 10:03:00,656 : INFO : EPOCH - 23 : training on 1100166 raw words (608091 effective words) took 1.4s, 423886 effective words/s\n",
            "2021-09-15 10:03:01,686 : INFO : EPOCH 24 - PROGRESS: at 68.14% examples, 408653 words/s, in_qsize 15, out_qsize 0\n",
            "2021-09-15 10:03:02,062 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2021-09-15 10:03:02,066 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2021-09-15 10:03:02,071 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2021-09-15 10:03:02,075 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2021-09-15 10:03:02,078 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-09-15 10:03:02,085 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-09-15 10:03:02,086 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-09-15 10:03:02,094 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-09-15 10:03:02,097 : INFO : EPOCH - 24 : training on 1100166 raw words (608475 effective words) took 1.4s, 427319 effective words/s\n",
            "2021-09-15 10:03:03,120 : INFO : EPOCH 25 - PROGRESS: at 64.50% examples, 389903 words/s, in_qsize 15, out_qsize 0\n",
            "2021-09-15 10:03:03,489 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2021-09-15 10:03:03,492 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2021-09-15 10:03:03,503 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2021-09-15 10:03:03,520 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2021-09-15 10:03:03,528 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-09-15 10:03:03,544 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-09-15 10:03:03,548 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-09-15 10:03:03,551 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-09-15 10:03:03,554 : INFO : EPOCH - 25 : training on 1100166 raw words (608525 effective words) took 1.4s, 422801 effective words/s\n",
            "2021-09-15 10:03:04,572 : INFO : EPOCH 26 - PROGRESS: at 66.34% examples, 402233 words/s, in_qsize 15, out_qsize 0\n",
            "2021-09-15 10:03:04,957 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2021-09-15 10:03:04,962 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2021-09-15 10:03:04,984 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2021-09-15 10:03:05,001 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2021-09-15 10:03:05,004 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-09-15 10:03:05,010 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-09-15 10:03:05,013 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-09-15 10:03:05,014 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-09-15 10:03:05,015 : INFO : EPOCH - 26 : training on 1100166 raw words (608443 effective words) took 1.4s, 421238 effective words/s\n",
            "2021-09-15 10:03:06,047 : INFO : EPOCH 27 - PROGRESS: at 67.24% examples, 405105 words/s, in_qsize 16, out_qsize 0\n",
            "2021-09-15 10:03:06,422 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2021-09-15 10:03:06,425 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2021-09-15 10:03:06,430 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2021-09-15 10:03:06,438 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2021-09-15 10:03:06,441 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-09-15 10:03:06,459 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-09-15 10:03:06,462 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-09-15 10:03:06,465 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-09-15 10:03:06,468 : INFO : EPOCH - 27 : training on 1100166 raw words (608814 effective words) took 1.4s, 425762 effective words/s\n",
            "2021-09-15 10:03:07,522 : INFO : EPOCH 28 - PROGRESS: at 68.14% examples, 404165 words/s, in_qsize 16, out_qsize 0\n",
            "2021-09-15 10:03:07,857 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2021-09-15 10:03:07,865 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2021-09-15 10:03:07,867 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2021-09-15 10:03:07,891 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2021-09-15 10:03:07,894 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-09-15 10:03:07,908 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-09-15 10:03:07,910 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-09-15 10:03:07,913 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-09-15 10:03:07,914 : INFO : EPOCH - 28 : training on 1100166 raw words (607879 effective words) took 1.4s, 429336 effective words/s\n",
            "2021-09-15 10:03:08,937 : INFO : EPOCH 29 - PROGRESS: at 69.01% examples, 417005 words/s, in_qsize 15, out_qsize 0\n",
            "2021-09-15 10:03:09,290 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2021-09-15 10:03:09,306 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2021-09-15 10:03:09,309 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2021-09-15 10:03:09,330 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2021-09-15 10:03:09,334 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-09-15 10:03:09,339 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-09-15 10:03:09,345 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-09-15 10:03:09,350 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-09-15 10:03:09,351 : INFO : EPOCH - 29 : training on 1100166 raw words (608422 effective words) took 1.4s, 428517 effective words/s\n",
            "2021-09-15 10:03:10,376 : INFO : EPOCH 30 - PROGRESS: at 63.59% examples, 382402 words/s, in_qsize 14, out_qsize 2\n",
            "2021-09-15 10:03:10,772 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2021-09-15 10:03:10,775 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2021-09-15 10:03:10,777 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2021-09-15 10:03:10,796 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2021-09-15 10:03:10,801 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-09-15 10:03:10,814 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-09-15 10:03:10,816 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-09-15 10:03:10,821 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-09-15 10:03:10,822 : INFO : EPOCH - 30 : training on 1100166 raw words (608241 effective words) took 1.5s, 417555 effective words/s\n",
            "2021-09-15 10:03:11,869 : INFO : EPOCH 31 - PROGRESS: at 68.11% examples, 401656 words/s, in_qsize 15, out_qsize 0\n",
            "2021-09-15 10:03:12,234 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2021-09-15 10:03:12,243 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2021-09-15 10:03:12,246 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2021-09-15 10:03:12,252 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2021-09-15 10:03:12,255 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-09-15 10:03:12,261 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-09-15 10:03:12,266 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-09-15 10:03:12,272 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-09-15 10:03:12,273 : INFO : EPOCH - 31 : training on 1100166 raw words (608364 effective words) took 1.4s, 423983 effective words/s\n",
            "2021-09-15 10:03:13,330 : INFO : EPOCH 32 - PROGRESS: at 67.24% examples, 394819 words/s, in_qsize 14, out_qsize 5\n",
            "2021-09-15 10:03:13,657 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2021-09-15 10:03:13,664 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2021-09-15 10:03:13,669 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2021-09-15 10:03:13,672 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2021-09-15 10:03:13,677 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2021-09-15 10:03:13,689 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2021-09-15 10:03:13,692 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2021-09-15 10:03:13,705 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2021-09-15 10:03:13,706 : INFO : EPOCH - 32 : training on 1100166 raw words (608350 effective words) took 1.4s, 429766 effective words/s\n",
            "2021-09-15 10:03:13,707 : INFO : training on a 35205312 raw words (19468926 effective words) took 46.5s, 418321 effective words/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1min 26s, sys: 715 ms, total: 1min 27s\n",
            "Wall time: 46.5 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19468926, 35205312)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Hwag2HPWFqA",
        "outputId": "0264ffa9-dedf-4453-fb97-5e780ff890ab"
      },
      "source": [
        "%%time\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df_train.text)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(\"Total words\", vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total words 77123\n",
            "CPU times: user 1.65 s, sys: 28 ms, total: 1.68 s\n",
            "Wall time: 1.69 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cipmijFn6fkO",
        "outputId": "a9b0df56-6cd0-4e70-a18e-c48e75e28aec"
      },
      "source": [
        "%%time\n",
        "x_train = pad_sequences(tokenizer.texts_to_sequences(df_train.text), maxlen=128)\n",
        "x_test = pad_sequences(tokenizer.texts_to_sequences(df_test.text), maxlen=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.89 s, sys: 36.9 ms, total: 1.93 s\n",
            "Wall time: 1.93 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKoy4LVs6Xcb",
        "outputId": "7eab3415-7d62-4da2-a343-02c8b596d51b"
      },
      "source": [
        "encoder = LabelEncoder()\n",
        "encoder.fit(df_train.sentiment.tolist())\n",
        "\n",
        "y_train = encoder.transform(df_train.sentiment.tolist())\n",
        "y_test = encoder.transform(df_test.sentiment.tolist())\n",
        "\n",
        "y_train = y_train.reshape(-1,1)\n",
        "y_test = y_test.reshape(-1,1)\n",
        "\n",
        "print(\"y_train\",y_train.shape)\n",
        "print(\"y_test\",y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train (70918, 1)\n",
            "y_test (17730, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rO5axkk8rph"
      },
      "source": [
        "def listToString(s): \n",
        "    \n",
        "    # initialize an empty string\n",
        "    str1 = \"\" \n",
        "    \n",
        "    # traverse in the string  \n",
        "    for ele in s: \n",
        "        str1 += ele  \n",
        "    \n",
        "    # return string  \n",
        "    return str1 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8kJkHYl2_qi"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.corpus import sentiwordnet as swn\n",
        "\n",
        "def senti(word):\n",
        "  splits = str.split(word)\n",
        "  postag = nltk.pos_tag(splits)\n",
        "  tagg = [tag for ( _, tag) in postag] \n",
        "  wn_tag = penn_to_wn(listToString(tagg))\n",
        "\n",
        "  try:\n",
        "    temp = wn.synsets(word, pos=wn_tag)\n",
        "    synset = temp[0]\n",
        "    swn_synset = swn.senti_synset(synset.name())\n",
        "    if swn_synset.pos_score() >= swn_synset.neg_score():\n",
        "      v_senti = np.array([swn_synset.pos_score()])\n",
        "    elif swn_synset.pos_score() < swn_synset.neg_score():\n",
        "      v_senti = np.array([-swn_synset.neg_score()])\n",
        "\n",
        "  except LookupError:\n",
        "    v_senti = np.array([0]) \n",
        "\n",
        "  return(v_senti)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J07Uu2rfDAcW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e65bd8a4-25d0-499b-d8ff-add10da378c6"
      },
      "source": [
        "def penn_to_wn(tag):\n",
        "    if tag.startswith('J'):\n",
        "        return wn.ADJ\n",
        "    elif tag.startswith('N'):\n",
        "        return wn.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wn.ADV\n",
        "    elif tag.startswith('V'):\n",
        "        return wn.VERB\n",
        "    return None\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size, 128))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "  if word in w2v_model.wv:\n",
        "    \n",
        "    v_senti2 = senti(word) \n",
        "    v_multi = np.concatenate((v_senti2,v_senti2,v_senti2,v_senti2,v_senti2,v_senti2,v_senti2,v_senti2,v_senti2))   \n",
        "    v_w2v = w2v_model.wv[word] \n",
        "    v_concat = np.concatenate((v_w2v,v_multi,v_multi,v_multi,v_multi)) \n",
        "\n",
        "    embedding_matrix[i] = v_concat\n",
        "print(embedding_matrix.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(77123, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYgBq3gJS8KT",
        "outputId": "44f28eb5-0690-46e2-d536-65fea80ec905"
      },
      "source": [
        "temp = wn.synsets(\"bad\", pos=\"a\")\n",
        "synset = temp[0]\n",
        "swn_synset = swn.senti_synset(synset.name())\n",
        "-swn_synset.neg_score()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.625"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqOXzOE5Z59e"
      },
      "source": [
        "embedding_layer = Embedding(vocab_size, 128, \n",
        "                            weights=[embedding_matrix], \n",
        "                            input_length=128, trainable=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hsX8DaKaCar",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80b244a3-ca22-4918-918a-fab1a2074168"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(embedding_layer)\n",
        "model.add(Bidirectional(LSTM(128,  return_sequences=True)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 128, 128)          9871744   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 128, 256)          263168    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128, 256)          0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128, 1)            257       \n",
            "=================================================================\n",
            "Total params: 10,135,169\n",
            "Trainable params: 10,135,169\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJ9gYUxublT5"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=\"Adam\",\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goqkKPjXbo9E"
      },
      "source": [
        "from keras import callbacks\n",
        "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\", \n",
        "                                        mode =\"min\", patience = 1,\n",
        "                                        restore_best_weights = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGtQ9RPJbtkr",
        "outputId": "16b808dd-7bc4-4b4b-ed8e-faeb23272ead"
      },
      "source": [
        "%%time\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=128,\n",
        "                    epochs=25,\n",
        "                    validation_split=0.3,\n",
        "                    verbose=1,\n",
        "                    callbacks=[earlystopping])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "388/388 [==============================] - 444s 1s/step - loss: 0.3632 - accuracy: 0.8471 - val_loss: 0.3775 - val_accuracy: 0.8351\n",
            "Epoch 2/25\n",
            "388/388 [==============================] - 443s 1s/step - loss: 0.2576 - accuracy: 0.9002 - val_loss: 0.3870 - val_accuracy: 0.8413\n",
            "CPU times: user 26min 10s, sys: 1min 43s, total: 27min 53s\n",
            "Wall time: 14min 47s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvuxVUX2oE6M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e4cdfc4-2bec-46a8-86ce-c79a02809330"
      },
      "source": [
        "%%time\n",
        "score = model.evaluate(x_test, y_test, batch_size=BATCH_SIZE)\n",
        "print()\n",
        "print(\"ACCURACY:\",score[1])\n",
        "print(\"LOSS:\",score[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "139/139 [==============================] - 39s 282ms/step - loss: 0.3815 - accuracy: 0.8312\n",
            "\n",
            "ACCURACY: 0.8311799168586731\n",
            "LOSS: 0.3815140426158905\n",
            "CPU times: user 1min 10s, sys: 3.8 s, total: 1min 13s\n",
            "Wall time: 41 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlDbL4-2o1cM"
      },
      "source": [
        "#def predict(text):\n",
        "#    start_at = time.time()\n",
        "#    # Tokenize text\n",
        "#    x_test = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen=128)\n",
        "    # Predict\n",
        "#    score = model.predict([x_test])\n",
        "\n",
        "\n",
        "#    return (score) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BkW7BHfBzrP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2293cabd-7565-4b3e-9f4e-0a7d4a4fb1b9"
      },
      "source": [
        "model.save(\"project_model.h5\")\n",
        "w2v_model.save(\"project.w2v\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-09-15 10:19:25,728 : INFO : saving Word2Vec object under project.w2v, separately None\n",
            "2021-09-15 10:19:25,732 : INFO : not storing attribute vectors_norm\n",
            "2021-09-15 10:19:25,734 : INFO : not storing attribute cum_table\n",
            "2021-09-15 10:19:25,782 : INFO : saved project.w2v\n"
          ]
        }
      ]
    }
  ]
}